{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.72:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week1\n",
    "\n",
    "#### Exercise 1 - Start your first pyspark app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'I remember I put on my socks,',\n",
       "  u'I remember I put on my shoes.',\n",
       "  u'I remember I put on my tie',\n",
       "  u'That was printed',\n",
       "  u'In beautiful purples and blues.',\n",
       "  u'I remember I put on my coat,',\n",
       "  u'To look perfectly grand at the dance,',\n",
       "  u'Yet I feel there is something',\n",
       "  u'I may have forgot\\u2014'],\n",
       " [u'What is it? What is it?...',\n",
       "  u'',\n",
       "  u'I made myself a snowball',\n",
       "  u'As perfect as could be.',\n",
       "  u'I thought I\\u2019d keep it as a pet',\n",
       "  u'And let it sleep with me.',\n",
       "  u'I made it some pajamas',\n",
       "  u'And a pillow for its head.',\n",
       "  u'  Then last night it ran away,',\n",
       "  u'  But first\\u2014it wet the bed.']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "lines.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.parallelize([\"spark\",\"spark is fun!\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],4)\n",
    "lines.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spark', 'spark is fun!'], ['1', '2'], ['3', '4'], ['5', '6']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'spark is fun!', '1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-1 Load a text file and split each line by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'I', u'remember', u'I', u'put', u'on', u'my', u'socks,'],\n",
       " [u'I', u'remember', u'I', u'put', u'on', u'my', u'shoes.'],\n",
       " [u'I', u'remember', u'I', u'put', u'on', u'my', u'tie'],\n",
       " [u'That', u'was', u'printed'],\n",
       " [u'In', u'beautiful', u'purples', u'and', u'blues.'],\n",
       " [u'I', u'remember', u'I', u'put', u'on', u'my', u'coat,'],\n",
       " [u'To', u'look', u'perfectly', u'grand', u'at', u'the', u'dance,'],\n",
       " [u'Yet', u'I', u'feel', u'there', u'is', u'something'],\n",
       " [u'I', u'may', u'have', u'forgot\\u2014'],\n",
       " [u'What', u'is', u'it?', u'What', u'is', u'it?...'],\n",
       " [],\n",
       " [u'I', u'made', u'myself', u'a', u'snowball'],\n",
       " [u'As', u'perfect', u'as', u'could', u'be.'],\n",
       " [u'I', u'thought', u'I\\u2019d', u'keep', u'it', u'as', u'a', u'pet'],\n",
       " [u'And', u'let', u'it', u'sleep', u'with', u'me.'],\n",
       " [u'I', u'made', u'it', u'some', u'pajamas'],\n",
       " [u'And', u'a', u'pillow', u'for', u'its', u'head.'],\n",
       " [u'Then', u'last', u'night', u'it', u'ran', u'away,'],\n",
       " [u'But', u'first\\u2014it', u'wet', u'the', u'bed.']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.map(lambda line : line.split())\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-2: Generate a list of words within one level structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I',\n",
       " u'remember',\n",
       " u'I',\n",
       " u'put',\n",
       " u'on',\n",
       " u'my',\n",
       " u'socks,',\n",
       " u'I',\n",
       " u'remember',\n",
       " u'I']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "words.collect()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-3: Find words including USF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I',\n",
       " u'remember',\n",
       " u'I',\n",
       " u'put',\n",
       " u'on',\n",
       " u'my',\n",
       " u'socks,',\n",
       " u'I',\n",
       " u'remember',\n",
       " u'I']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = words.filter(lambda lines : lines is not u'')\n",
    "words.collect()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-4: Do the same with mapPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[u'I\",\n",
       " 'remember',\n",
       " 'I',\n",
       " 'put',\n",
       " 'on',\n",
       " 'my',\n",
       " \"socks,',\",\n",
       " \"u'I\",\n",
       " 'remember',\n",
       " 'I',\n",
       " 'put',\n",
       " 'on',\n",
       " 'my',\n",
       " \"shoes.',\",\n",
       " \"u'I\",\n",
       " 'remember',\n",
       " 'I',\n",
       " 'put',\n",
       " 'on',\n",
       " 'my',\n",
       " \"tie',\",\n",
       " \"u'That\",\n",
       " 'was',\n",
       " \"printed',\",\n",
       " \"u'In\",\n",
       " 'beautiful',\n",
       " 'purples',\n",
       " 'and',\n",
       " \"blues.',\",\n",
       " \"u'I\",\n",
       " 'remember',\n",
       " 'I',\n",
       " 'put',\n",
       " 'on',\n",
       " 'my',\n",
       " \"coat,',\",\n",
       " \"u'To\",\n",
       " 'look',\n",
       " 'perfectly',\n",
       " 'grand',\n",
       " 'at',\n",
       " 'the',\n",
       " \"dance,',\",\n",
       " \"u'Yet\",\n",
       " 'I',\n",
       " 'feel',\n",
       " 'there',\n",
       " 'is',\n",
       " \"something',\",\n",
       " \"u'I\",\n",
       " 'may',\n",
       " 'have',\n",
       " \"forgot\\\\u2014']\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_function(partition):\n",
    "        word = str(list(partition)).split()\n",
    "        yield word\n",
    "words = lines.mapPartitions(split_function)\n",
    "words.collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-5:  use mapPartitionsWithIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_function_index(index, partition):\n",
    "        word =  str(list(partition)).split()\n",
    "        output =  str(index) + \":\" + str(word) \n",
    "        yield output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0:[\"[u\\'I\", \\'remember\\', \\'I\\', \\'put\\', \\'on\\', \\'my\\', \"socks,\\',\", \"u\\'I\", \\'remember\\', \\'I\\', \\'put\\', \\'on\\', \\'my\\', \"shoes.\\',\", \"u\\'I\", \\'remember\\', \\'I\\', \\'put\\', \\'on\\', \\'my\\', \"tie\\',\", \"u\\'That\", \\'was\\', \"printed\\',\", \"u\\'In\", \\'beautiful\\', \\'purples\\', \\'and\\', \"blues.\\',\", \"u\\'I\", \\'remember\\', \\'I\\', \\'put\\', \\'on\\', \\'my\\', \"coat,\\',\", \"u\\'To\", \\'look\\', \\'perfectly\\', \\'grand\\', \\'at\\', \\'the\\', \"dance,\\',\", \"u\\'Yet\", \\'I\\', \\'feel\\', \\'there\\', \\'is\\', \"something\\',\", \"u\\'I\", \\'may\\', \\'have\\', \"forgot\\\\\\\\u2014\\']\"]',\n",
       " '1:[\"[u\\'What\", \\'is\\', \\'it?\\', \\'What\\', \\'is\\', \"it?...\\',\", \"u\\'\\',\", \"u\\'I\", \\'made\\', \\'myself\\', \\'a\\', \"snowball\\',\", \"u\\'As\", \\'perfect\\', \\'as\\', \\'could\\', \"be.\\',\", \"u\\'I\", \\'thought\\', \\'I\\\\\\\\u2019d\\', \\'keep\\', \\'it\\', \\'as\\', \\'a\\', \"pet\\',\", \"u\\'And\", \\'let\\', \\'it\\', \\'sleep\\', \\'with\\', \"me.\\',\", \"u\\'I\", \\'made\\', \\'it\\', \\'some\\', \"pajamas\\',\", \"u\\'And\", \\'a\\', \\'pillow\\', \\'for\\', \\'its\\', \"head.\\',\", \"u\\'\", \\'Then\\', \\'last\\', \\'night\\', \\'it\\', \\'ran\\', \"away,\\',\", \"u\\'\", \\'But\\', \\'first\\\\\\\\u2014it\\', \\'wet\\', \\'the\\', \"bed.\\']\"]']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.mapPartitionsWithIndex(split_function_index)\n",
    "words.collect()[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1-6: try sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I',\n",
       " u'on',\n",
       " u'blues.',\n",
       " u'on',\n",
       " u'What',\n",
       " u'it?...',\n",
       " u'be.',\n",
       " u'And',\n",
       " u'head.',\n",
       " u'it']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "words.sample(True,0.10,1).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'put', u'I', u'put', u'I', u'beautiful', u'there', u'And', u'me.', u'']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sample(False,0.10,1).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Parallelize numbers between 1 and 16. Calculate the count and sum in each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(1,17))\n",
    "numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [2, 7], [2, 11], [2, 15], [2, 19], [2, 23], [2, 27], [2, 31]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_sum(nums):\n",
    "    count_sum = [0,0]\n",
    "    for num in nums:\n",
    "        count_sum[0] += 1\n",
    "        count_sum[1] += num\n",
    "    return [count_sum]\n",
    "\n",
    "partition_count_sum = numbers.mapPartitions(count_sum)\n",
    "partition_count_sum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16, 136], 8.5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_sum = partition_count_sum.reduce(lambda x,y : [x[0]+y[0],x[1]+y[1]])\n",
    "average = float(total_count_sum[1])/float(total_count_sum[0])\n",
    "total_count_sum, average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1], [1, 2]],\n",
       " [[1, 3], [1, 4]],\n",
       " [[1, 5], [1, 6]],\n",
       " [[1, 7], [1, 8]],\n",
       " [[1, 9], [1, 10]],\n",
       " [[1, 11], [1, 12]],\n",
       " [[1, 13], [1, 14]],\n",
       " [[1, 15], [1, 16]]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_num = numbers.map(lambda x: [1,x])\n",
    "one_num.glom().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([16, 136], 8.5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sum = one_num.reduce(lambda x,y :[x[0]+y[0],x[1]+y[1]])\n",
    "average = float(count_sum[1])/float(count_sum[0])\n",
    "count_sum, average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3-1: Find distinct words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'beautiful', u'and', u'What', u'feel', u'is']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_1 = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words_1 = lines_1.flatMap(lambda line : line.split())\n",
    "distinct_words_1 = words_1.distinct()\n",
    "distinct_words_1.collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3-2: Create  a `flatmap` of distinct words\n",
    "#### Example 3-3: What is the union, intersection, subtract, and cartesian product of the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'beautiful', u'and', u'What', u'feel', u'is']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_2 = sc.textFile(\"./examples/Data/applenews_sm.txt\")\n",
    "words_2 = lines_2.flatMap(lambda line : line.split())\n",
    "distinct_words_2 = words_2.distinct()\n",
    "distinct_words_1.union(distinct_words_2).collect()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'and', u'feel', u'was', u'a', u'it']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words_1.intersection(distinct_words_2).collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'beautiful', u'some', u'ran', u'sleep', u'pajamas']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words_1.subtract(distinct_words_2).collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'beautiful', u'control'),\n",
       " (u'beautiful', u'and'),\n",
       " (u'beautiful', u'lists'),\n",
       " (u'beautiful', u'Dye,'),\n",
       " (u'beautiful', u'feel')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words_1.cartesian(distinct_words_2).collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [3], [4], [5], [6], [7], [8, 9]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums =  sc.parallelize(range(1,10))\n",
    "nums.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [5, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = sc.parallelize(range(1,10),2)\n",
    "nums.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4-1: For the numbers between 1 and 9, calculate sum of the odd numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "odd_num = nums.filter(lambda a : a%2 == 1)\n",
    "print odd_num.reduce(lambda a,b : a+b)\n",
    "print odd_num.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4-2:  For the numbers between 1 and 9, calculate sum of the odd numbers using fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print odd_num.fold(0, lambda a,b : a+b)\n",
    "print odd_num.fold(1, lambda a,b : a+b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [5, 7, 9]]\n",
      "(5, 25)\n"
     ]
    }
   ],
   "source": [
    "print odd_num.glom().collect()\n",
    "print odd_num.aggregate((0,0),(lambda x,y: (x[0]+1,x[1]+y)),(lambda x,y : (x[0]+y[0],x[1]+y[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5: given, Try collect(), count(), countByValue(), top(n), take(n),first(),takeSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize([3,4,1,2])\n",
    "y = sc.parallelize(range(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [3], [], [4], [], [1], [], [2], [], [2], [], [3], [], [4], [], [5]]\n",
      "[3, 4, 1, 2, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "z = x.union(y)\n",
    "print z.glom().collect()\n",
    "print z.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "defaultdict(<type 'int'>, {1: 1, 2: 2, 3: 2, 4: 2, 5: 1})\n",
      "[5, 4, 4, 3, 3, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print z.count()\n",
    "print z.countByValue()\n",
    "print z.top(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1, 2, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print z.take(8)\n",
    "print z.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3, 5, 3, 1, 4]\n",
      "[4, 1, 3, 4, 4, 4, 3, 4, 2, 4, 3, 3, 3, 2, 2, 3, 2, 3, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "print z.takeSample(False,20)\n",
    "print z.takeSample(True,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6: Write a python script and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#Create SparkContext\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"read_lines\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "#Load Data.\n",
    "lines=sc.textFile(\"../Data/README.md\")\n",
    "print(lines.count())\n",
    "print(lines.first())\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Extract all the words , generate key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'I', 1), (u'remember', 1), (u'I', 1), (u'put', 1), (u'on', 1), (u'my', 1), (u'socks,', 1), (u'I', 1), (u'remember', 1), (u'I', 1)]\n",
      "[(1, 1), (8, 1), (1, 1), (3, 1), (2, 1), (2, 1), (6, 1), (1, 1), (8, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "word_map = words.map(lambda x : (x,1))\n",
    "print word_map.collect()[:10]\n",
    "word_map = words.map(lambda x : (len(x), 1))\n",
    "print word_map.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: From the README.md file, generate key-value pairs of (length of word, words) using keys(), values(), sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 1, 3, 2, 2, 6, 1, 8, 1]\n",
      "------------------------\n",
      "[u'I', u'remember', u'I', u'put', u'on', u'my', u'socks,', u'I', u'remember', u'I']\n",
      "------------------------\n",
      "[(1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I')]\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "len_word_pair = words.map(lambda x : (len(x),x))\n",
    "print len_word_pair.keys().collect()[:10]\n",
    "print '------------------------'\n",
    "print len_word_pair.values().collect()[:10]\n",
    "print '------------------------'\n",
    "print len_word_pair.sortByKey().collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3 : Create a pair RDD with (length of word, list of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, <pyspark.resultiterable.ResultIterable object at 0x109ae5c90>), (2, <pyspark.resultiterable.ResultIterable object at 0x10998f410>)]\n",
      "------------------------\n",
      "[(8, [u'remember', u'remember', u'remember', u'remember', u'snowball', u'first\\u2014it']), (2, [u'on', u'my', u'on', u'my', u'on', u'my', u'In', u'on', u'my', u'To', u'at', u'is', u'is', u'is', u'As', u'as', u'it', u'as', u'it', u'it', u'it'])]\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "len_word_pair = words.map(lambda x : (len(x),x))\n",
    "len_word_pair_group = len_word_pair.groupByKey()\n",
    "print len_word_pair_group.collect()[:2]\n",
    "print '------------------------'\n",
    "print len_word_pair_group.map(lambda x : (x[0], list(x[1]))).collect()[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: From the README.md, generate key-value pairs of (word, occurrence) using mapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(u'I', 1), (u'remember', 1), (u'I', 1), (u'put', 1), (u'on', 1), (u'my', 1), (u'socks,', 1), (u'I', 1), (u'remember', 1), (u'I', 1), (u'put', 1), (u'on', 1), (u'my', 1), (u'shoes.', 1), (u'I', 1), (u'remember', 1), (u'I', 1), (u'put', 1), (u'on', 1), (u'my', 1), (u'tie', 1), (u'That', 1), (u'was', 1), (u'printed', 1), (u'In', 1), (u'beautiful', 1), (u'purples', 1), (u'and', 1), (u'blues.', 1), (u'I', 1), (u'remember', 1), (u'I', 1), (u'put', 1), (u'on', 1), (u'my', 1), (u'coat,', 1), (u'To', 1), (u'look', 1), (u'perfectly', 1), (u'grand', 1), (u'at', 1), (u'the', 1), (u'dance,', 1), (u'Yet', 1), (u'I', 1), (u'feel', 1), (u'there', 1), (u'is', 1), (u'something', 1), (u'I', 1), (u'may', 1), (u'have', 1), (u'forgot\\u2014', 1)], [(u'What', 1), (u'is', 1), (u'it?', 1), (u'What', 1), (u'is', 1), (u'it?...', 1), (u'I', 1), (u'made', 1), (u'myself', 1), (u'a', 1), (u'snowball', 1), (u'As', 1), (u'perfect', 1), (u'as', 1), (u'could', 1), (u'be.', 1), (u'I', 1), (u'thought', 1), (u'I\\u2019d', 1), (u'keep', 1), (u'it', 1), (u'as', 1), (u'a', 1), (u'pet', 1), (u'And', 1), (u'let', 1), (u'it', 1), (u'sleep', 1), (u'with', 1), (u'me.', 1), (u'I', 1), (u'made', 1), (u'it', 1), (u'some', 1), (u'pajamas', 1), (u'And', 1), (u'a', 1), (u'pillow', 1), (u'for', 1), (u'its', 1), (u'head.', 1), (u'Then', 1), (u'last', 1), (u'night', 1), (u'it', 1), (u'ran', 1), (u'away,', 1), (u'But', 1), (u'first\\u2014it', 1), (u'wet', 1), (u'the', 1), (u'bed.', 1)]]\n",
      "------------------------\n",
      "[(u'beautiful', 1), (u'and', 1), (u'What', 2), (u'feel', 1), (u'is', 3)]\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "word_rdd = words.map(lambda x : (x,1))\n",
    "print word_rdd.glom().collect() [:6]\n",
    "grouped_word_rdd = word_rdd.groupByKey()\n",
    "#print grouped_word_rdd.glom().collect()\n",
    "word_count = grouped_word_rdd.mapValues(lambda x : sum(x))\n",
    "print '------------------------'\n",
    "print word_count.collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5: Create a list of (len, word) pairs from W3.3 len_word_pair_group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(8, <pyspark.resultiterable.ResultIterable object at 0x109acbe10>), (2, <pyspark.resultiterable.ResultIterable object at 0x109acb210>), (4, <pyspark.resultiterable.ResultIterable object at 0x109ad6690>), (6, <pyspark.resultiterable.ResultIterable object at 0x109ad6990>)], [(1, <pyspark.resultiterable.ResultIterable object at 0x109ad62d0>), (3, <pyspark.resultiterable.ResultIterable object at 0x109ad6b90>), (9, <pyspark.resultiterable.ResultIterable object at 0x109ad6610>), (5, <pyspark.resultiterable.ResultIterable object at 0x109ad6250>), (7, <pyspark.resultiterable.ResultIterable object at 0x109ad6c10>)]]\n",
      "------------------------\n",
      "[[(8, u'remember'), (8, u'remember'), (8, u'remember'), (8, u'remember'), (8, u'snowball'), (8, u'first\\u2014it'), (2, u'on'), (2, u'my'), (2, u'on'), (2, u'my'), (2, u'on'), (2, u'my'), (2, u'In'), (2, u'on'), (2, u'my'), (2, u'To'), (2, u'at'), (2, u'is'), (2, u'is'), (2, u'is'), (2, u'As'), (2, u'as'), (2, u'it'), (2, u'as'), (2, u'it'), (2, u'it'), (2, u'it'), (4, u'That'), (4, u'look'), (4, u'feel'), (4, u'have'), (4, u'What'), (4, u'What'), (4, u'made'), (4, u'keep'), (4, u'with'), (4, u'made'), (4, u'some'), (4, u'Then'), (4, u'last'), (4, u'bed.'), (6, u'socks,'), (6, u'shoes.'), (6, u'blues.'), (6, u'dance,'), (6, u'it?...'), (6, u'myself'), (6, u'pillow')], [(1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'I'), (1, u'a'), (1, u'I'), (1, u'a'), (1, u'I'), (1, u'a'), (3, u'put'), (3, u'put'), (3, u'put'), (3, u'tie'), (3, u'was'), (3, u'and'), (3, u'put'), (3, u'the'), (3, u'Yet'), (3, u'may'), (3, u'it?'), (3, u'be.'), (3, u'I\\u2019d'), (3, u'pet'), (3, u'And'), (3, u'let'), (3, u'me.'), (3, u'And'), (3, u'for'), (3, u'its'), (3, u'ran'), (3, u'But'), (3, u'wet'), (3, u'the'), (9, u'beautiful'), (9, u'perfectly'), (9, u'something'), (5, u'coat,'), (5, u'grand'), (5, u'there'), (5, u'could'), (5, u'sleep'), (5, u'head.'), (5, u'night'), (5, u'away,'), (7, u'printed'), (7, u'purples'), (7, u'forgot\\u2014'), (7, u'perfect'), (7, u'thought'), (7, u'pajamas')]]\n",
      "------------------------\n",
      "[[(1, u'I'), (8, u'remember'), (1, u'I'), (3, u'put'), (2, u'on'), (2, u'my'), (6, u'socks,'), (1, u'I'), (8, u'remember'), (1, u'I'), (3, u'put'), (2, u'on'), (2, u'my'), (6, u'shoes.'), (1, u'I'), (8, u'remember'), (1, u'I'), (3, u'put'), (2, u'on'), (2, u'my'), (3, u'tie'), (4, u'That'), (3, u'was'), (7, u'printed'), (2, u'In'), (9, u'beautiful'), (7, u'purples'), (3, u'and'), (6, u'blues.'), (1, u'I'), (8, u'remember'), (1, u'I'), (3, u'put'), (2, u'on'), (2, u'my'), (5, u'coat,'), (2, u'To'), (4, u'look'), (9, u'perfectly'), (5, u'grand'), (2, u'at'), (3, u'the'), (6, u'dance,'), (3, u'Yet'), (1, u'I'), (4, u'feel'), (5, u'there'), (2, u'is'), (9, u'something'), (1, u'I'), (3, u'may'), (4, u'have'), (7, u'forgot\\u2014')], [(4, u'What'), (2, u'is'), (3, u'it?'), (4, u'What'), (2, u'is'), (6, u'it?...'), (1, u'I'), (4, u'made'), (6, u'myself'), (1, u'a'), (8, u'snowball'), (2, u'As'), (7, u'perfect'), (2, u'as'), (5, u'could'), (3, u'be.'), (1, u'I'), (7, u'thought'), (3, u'I\\u2019d'), (4, u'keep'), (2, u'it'), (2, u'as'), (1, u'a'), (3, u'pet'), (3, u'And'), (3, u'let'), (2, u'it'), (5, u'sleep'), (4, u'with'), (3, u'me.'), (1, u'I'), (4, u'made'), (2, u'it'), (4, u'some'), (7, u'pajamas'), (3, u'And'), (1, u'a'), (6, u'pillow'), (3, u'for'), (3, u'its'), (5, u'head.'), (4, u'Then'), (4, u'last'), (5, u'night'), (2, u'it'), (3, u'ran'), (5, u'away,'), (3, u'But'), (8, u'first\\u2014it'), (3, u'wet'), (3, u'the'), (4, u'bed.')]]\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "len_word_pair = words.map(lambda x : (len(x),x))\n",
    "print len_word_pair_group.mapValues(lambda x : x).glom().collect()\n",
    "print '------------------------'\n",
    "print len_word_pair_group.flatMapValues(lambda x : x).glom().collect()\n",
    "print '------------------------'\n",
    "print len_word_pair.glom().collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6: From the README.md, generate key-value pairs of (word, occurrence) using reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'beautiful', 1),\n",
       " (u'and', 1),\n",
       " (u'What', 2),\n",
       " (u'feel', 1),\n",
       " (u'is', 3),\n",
       " (u'some', 1),\n",
       " (u'as', 2),\n",
       " (u'sleep', 1),\n",
       " (u'But', 1),\n",
       " (u'have', 1)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/sm.txt\")\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "word_rdd = words.map(lambda x : (x,1))\n",
    "word_count = word_rdd.reduceByKey(lambda x,y : x+y)\n",
    "word_count.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1:Using “filtered_registered_business_sf.csv” and “supervisor_sf.csv”, list business names without a district supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'94103', u'Razaghi A Kiakojouri A'),\n",
       " (u'94590', u'Julio Cesar De Moraes'),\n",
       " (u'94103', u'Bernies Pet Shoppe Inc'),\n",
       " (u'94122', u'Chan Cindy L'),\n",
       " (u'94124', u'Ho Kwok M')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = sc.textFile(\"./examples/Data/filtered_registered_business_sf.csv\")\n",
    "business_zip_name_pair = business.map(lambda x : x.split(\",\"))\\\n",
    "                                .map(lambda x : (x[0],x[1])).distinct()\n",
    "business_zip_name_pair.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'94118', u'1'),\n",
       " (u'94134', u'9'),\n",
       " (u'94118', u'5'),\n",
       " (u'94134', u'11'),\n",
       " (u'94111', u'6')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor = sc.textFile(\"./examples/Data/supervisor_sf.csv\")\n",
    "supervisor_zip_id_pair = supervisor.map(lambda x : x.split(\",\"))\\\n",
    "                                   .map(lambda x : (x[0],x[1])).distinct()\n",
    "supervisor_zip_id_pair.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'Precision Communication Serv',\n",
       " u'Schefer Thomas R',\n",
       " u'Lucid Systems',\n",
       " u'Jacob Abraham',\n",
       " u'Daniel Dela Rosa',\n",
       " u'Sudhir Marahatta',\n",
       " u'Batista Luis S',\n",
       " u'\"Wti',\n",
       " u'Boutin Jacqueline M',\n",
       " u'Avinesh P Singh']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_without_supervisor = business_zip_name_pair.subtractByKey(supervisor_zip_id_pair)\\\n",
    "                                                    .values()\\\n",
    "                                                    .distinct()\n",
    "print business_without_supervisor.count()\n",
    "business_without_supervisor.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2:\n",
    "\n",
    "    # What are the results of? \n",
    "    first_num_pairs.subtract(second_num_pairs)\n",
    "    first_num_pairs.subtractByKey(second_num_pairs)\n",
    "    first_num_pairs.join(second_num_pairs)\n",
    "    first_num_pairs.rightOuterJoin(second_num_pairs)\n",
    "    first_num_pairs.leftOuterJoin(second_num_pairs)\n",
    "    first_num_pairs.cogroup(second_num_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 3), (3, 6), (1, 2), (2, 4)]\n",
      "[(3, 6)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "first_num_pairs = sc.parallelize({(2,3),(1,2),(1,3),(2,4),(3,6)})\n",
    "second_num_pairs = sc.parallelize({(1,3),(2,2)})\n",
    "print first_num_pairs.subtract(second_num_pairs).collect()\n",
    "print first_num_pairs.subtractByKey(second_num_pairs).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (2, 3)), (1, (3, 3)), (2, (3, 2)), (2, (4, 2))]\n",
      "[(1, (2, 3)), (1, (3, 3)), (2, (3, 2)), (2, (4, 2))]\n",
      "[(1, (2, 3)), (1, (3, 3)), (2, (3, 2)), (2, (4, 2)), (3, (6, None))]\n"
     ]
    }
   ],
   "source": [
    "print first_num_pairs.join(second_num_pairs).collect()\n",
    "print first_num_pairs.rightOuterJoin(second_num_pairs).collect()\n",
    "print first_num_pairs.leftOuterJoin(second_num_pairs).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (<pyspark.resultiterable.ResultIterable object at 0x109bcfa50>, <pyspark.resultiterable.ResultIterable object at 0x109ae5450>)), (2, (<pyspark.resultiterable.ResultIterable object at 0x109ae5ed0>, <pyspark.resultiterable.ResultIterable object at 0x109ae5fd0>)), (3, (<pyspark.resultiterable.ResultIterable object at 0x109ae56d0>, <pyspark.resultiterable.ResultIterable object at 0x109ae53d0>))]\n",
      "[(1, ([2, 3], [3])), (2, ([3, 4], [2])), (3, ([6], []))]\n",
      "defaultdict(<type 'int'>, {1: 2, 2: 2, 3: 1})\n"
     ]
    }
   ],
   "source": [
    "print first_num_pairs.cogroup(second_num_pairs).collect()\n",
    "print first_num_pairs.cogroup(second_num_pairs).map(lambda x : (x[0], (list(x[1][0]), list(x[1][1])))).collect()\n",
    "print first_num_pairs.countByKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "\n",
    "- Using W4.1, list (zip,(business_name, supervisor_id)) pairs ordered by supervisor_id\n",
    "  - Only if both business and supervisor exist\n",
    "  - If a business exists\n",
    "  - If a supervisor exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'94112', (u'Tradicion Peruana Cultural Cnt', u'9')),\n",
       " (u'94112', (u'Houston Victorene P', u'9')),\n",
       " (u'94112', (u'Sole Prop Daniel Castellanos', u'9')),\n",
       " (u'94112', (u'Baysac Belanio G & Carmen S', u'9')),\n",
       " (u'94112', (u'Piskov Oksana', u'9')),\n",
       " (u'94112', (u'Navarro Miguel & Joanne', u'9')),\n",
       " (u'94112', (u'Jing Luo', u'9')),\n",
       " (u'94112', (u'Bustillo Gloria Maria Ulloa', u'9')),\n",
       " (u'94112', (u'Lai Seu Wannie/gu Wei', u'9')),\n",
       " (u'94112', (u'Chiu Chong Ying', u'9'))]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = sc.textFile(\"./examples/Data/filtered_registered_business_sf.csv\")\n",
    "business_zip_name_pair = business.map(lambda x : x.split(\",\"))\\\n",
    "                                .map(lambda x : (x[0],x[1])).distinct()\n",
    "supervisor = sc.textFile(\"./examples/Data/supervisor_sf.csv\")\n",
    "supervisor_zip_id_pair = supervisor.map(lambda x : x.split(\",\"))\\\n",
    "                                   .map(lambda x : (x[0],x[1])).distinct()\n",
    "    \n",
    "business_join_supervisor = business_zip_name_pair.join(supervisor_zip_id_pair)\n",
    "business_join_supervisor.sortBy(lambda x : x[1][1], ascending = False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_left_join_supervisor = business_zip_name_pair.leftOuterJoin(supervisor_zip_id_pair)\n",
    "business_right_join_supervisor = business_zip_name_pair.rightOuterJoin(supervisor_zip_id_pair)\n",
    "business_join_supervisor.subtract(business_right_join_supervisor).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4\n",
    "Generate Key(zip) and value pair RDDs from “filtered_registered_business_sf.csv” and “supervisor_sf.csv” and cogroup() the RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'', ([u'Opower Inc', u'Poco Petroleum Inc', u'Rice Paradise Llc', u'Cantrell Harris & Assoc Inc', u'Cooper Jim B', u'Arconas Corporation', u'Woo H Woo S', u'221 7th Street Residences Llc', u'1625 Leavenworth Street Llc', u'Bond Blacktop Inc', u'Bibliocommons Inc', u'Ortiz Jose E', u'Eldred Robert J Cfp', u'Endurance Wind Power Inc', u'Joseph D & Candice M Harney Trust Jc & Cm Harney Trust', u'Cardno Entrix', u'Paybyphone Technologies Inc', u'Willis Supply Corporation', u'New Flyer Industriescanada Ulc', u'Vip Plumbing And Drain Cleanin', u'Htut Chris', u'Mid Canada Millwork Ltd', u'Act Fuels Inc', u'Allstream Inc', u'Radio Ip Software Inc', u'C Fischer And Sons Llc', u'Abd Insurance & Financial Serv', u'Built 1925 Llc', u'Ramon Chavez', u'Cirque Du Soleil Inc', u'Law Office Of Scott A Sommer', u'Moonka Nishi', u'Hampton Court Sf Lp', u'Margaret Apartments Lp', u'Magdaluyo Melecio', u'Uniacke J Uniacke M', u'Gala Systems Inc', u'Red Oxygen Inc', u'Sara Gulyas', u'Sfe Energy California Inc', u'Lexa Mary C', u'Cast Connex Corporation', u'Ascencion Flores Ismael O', u'Pointclickcare', u'Miniclip America Inc', u'Atc Managed Sites Llc', u'Intelex Technologies Inc', u'Barth Roofing Company Inc', u'Golden Bay Roofing Inc', u'Fairman Mark', u'1st Impression Construction Inc', u'East & West Alum Craft Inc', u'Leo And Janis Paslin Trust', u'Vieira Reynaldo', u'Siemens Public', u'Intelligent Hospital Systems', u'Philz Coffee Inc', u'Ultra Electronics Forensic Technology Inc', u'Torres Alvaro', u'Morse Fred', u'Fts Forest Tech Systems Ltd', u'Viavid Broadcasting Inc', u'Iotum Inc', u'Malik Alia', u'Delcan Corporation', u'Odotech Inc', u'Nada Pacific Corporation', u'Hartmann Studios Incorporated'], [])), (u'70363', ([u'Saia Motor Freight Line Llc'], [])), (u'19443', ([u'Teva Pharmaceuticals Usa Inc'], [])), (u'28036', ([u'\"Norman Technologies'], [])), (u'73018', ([u'Nw Sign Industries Inc'], [])), (u'83530', ([u'\"Compunet'], [])), (u'44122', ([u'\"Cooper Wheelock', u'Weatherproofing Tech Inc', u'Checkpoint Surgical Llc', u'\"Cannon Technologies', u'\"Cooper Wiring Devices', u'\"Eaton Us Holdings', u'\"Cooper B-Line', u'Cooper Notification Inc.'], [])), (u'95627', ([u'Phillip Kess', u'Cooper Grant', u'Huynh Kimberly C', u'Sanford Mike V'], [])), (u'94008', ([u'Williams Thomas R'], [])), (u'95623', ([u'Laurin Geoffrey A'], []))]\n",
      "------------------------\n",
      "[(u'', (68, 0)), (u'70363', (1, 0)), (u'19443', (1, 0)), (u'28036', (1, 0)), (u'73018', (1, 0)), (u'83530', (1, 0)), (u'44122', (8, 0)), (u'95627', (4, 0)), (u'94008', (1, 0)), (u'95623', (1, 0))]\n"
     ]
    }
   ],
   "source": [
    "business = sc.textFile(\"./examples/Data/filtered_registered_business_sf.csv\")\n",
    "business_zip_name_pair = business.map(lambda x : x.split(\",\"))\\\n",
    "                                .map(lambda x : (x[0],x[1])).distinct()\n",
    "supervisor = sc.textFile(\"./examples/Data/supervisor_sf.csv\")\n",
    "supervisor_zip_id_pair = supervisor.map(lambda x : x.split(\",\"))\\\n",
    "                                   .map(lambda x : (x[0],x[1])).distinct()\n",
    "    \n",
    "business_supervisor_group = business_zip_name_pair.cogroup(supervisor_zip_id_pair)\n",
    "\n",
    "business_supervisor_group.collect()\n",
    "print business_supervisor_group.map(lambda x : (x[0],(list(x[1][0]), list(x[1][1])))).collect()[:10]\n",
    "print '------------------------'\n",
    "print business_supervisor_group.map(lambda x : (x[0],(len(list(x[1][0])), len(list(x[1][1]))))).collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5\n",
    "\n",
    "\n",
    "- From ”filtered_registered_business_sf.csv”, create a pair RDD of (zip, (store name, city))\n",
    "  - Count pairs which don’t have a key\n",
    "  - Filter pairs that don’t include“San Francisco” in the city value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'94123', (u'Tournahu George L', u'San Francisco')),\n",
       " (u'94124', (u'Stephens Institute Inc', u'San Francisco')),\n",
       " (u'94105', (u'Stephens Institute Inc', u'San Francisco')),\n",
       " (u'94108', (u'Stephens Institute Inc', u'San Francisco')),\n",
       " (u'94107', (u'Stephens Institute Inc', u'San Francisco'))]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/filtered_registered_business_sf.csv\")\n",
    "pairs = lines.map(lambda x: (x.split(\",\")[0], (x.split(\",\")[1],x.split(\",\")[3])))\n",
    "pairs.collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 92), (u'92397', 1), (u'55344', 5), (u'55346', 1), (u'55343', 11)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.countByKey().items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', (u'Siemens Public', u'Indianapolis')),\n",
       " (u'10037', (u'Eyebite Productions Inc', u'New+york')),\n",
       " (u'92397', (u'Kernan Bart C', u'Wrightwood')),\n",
       " (u'55344', (u'Optum360 Llc', u'Eden+prairie')),\n",
       " (u'55346', (u'Celleration Inc', u'Eden+prairie'))]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.collectAsMap().items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Hartmann Studios Incorporated', u''),\n",
       " (u'Cardno Entrix', u''),\n",
       " (u'Bond Blacktop Inc', u''),\n",
       " (u'Moonka Nishi', u''),\n",
       " (u'Cooper Jim B', u'')]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.lookup('')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs.lookup(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'94108', (u'\"Fugazi Travel Agency', u'170 Grant Ave 4th Fl')),\n",
       " (u'94111', (u'\"Fugazi Travel Agency', u'400 Sansome St')),\n",
       " (u'94111', (u'\"Fugazi Travel Agency', u'400 Sansome St')),\n",
       " (u'94111', (u'\"Fugazi Travel Agency', u'400 Sansome St')),\n",
       " (u'94111', (u'\"Fugazi Travel Agency', u'400 Sansome St'))]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.filter(lambda x: \"San Francisco\" not in x[1][1]).collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6 - Used a big file to download and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Try different persistency levels on RDDs which include “Sparks”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 1x Replicated\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"./examples/Data/README.md\")\n",
    "lines_with_Spark = lines.filter(lambda x : \"Spark\" in x)\n",
    "print lines_with_Spark.getStorageLevel()\n",
    "print lines_with_Spark.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.persist()\n",
    "lines_with_Spark.count() # DATA IS PERSISTED ONCE YOU CALL AN ACTION. (SEE THE WEB UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1003] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.cache()\n",
    "lines_with_Spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1003] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, False, False, False, 1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "lines_with_Spark.persist(StorageLevel.DISK_ONLY) #WHAT HAPPENS?\n",
    "lines_with_Spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 2)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.unpersist()\n",
    "lines_with_Spark.persist(StorageLevel.MEMORY_ONLY_2)\n",
    "lines_with_Spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1003] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.unpersist()\n",
    "lines_with_Spark.persist(StorageLevel.OFF_HEAP) #UNPERSIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1003] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_Spark.unpersist()\n",
    "lines_with_Spark.persist(StorageLevel(False,True,False,False,3)) #UNPERSIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'# Apache Spark', u'Spark is a fast and general cluster computing system for Big Data. It provides']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print lines_with_Spark.take(2) # DATA IS PERSISTED ONCE YOU CALL AN ACTION. (SEE THE WEB UI)\n",
    "print lines_with_Spark.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5\n",
    "```python\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setMaster(\"spark://ip-172-31-17-229.us-west-2.compute.internal:7077\").setAppName(\"Woodbridge_Diane\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "print  sc.parallelize([1,2,3,4]).mean()\n",
    "\n",
    "print sc.textFile(\"file:///root/example/input_2.txt\").count()\n",
    "\n",
    "sc.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Load all the .csv files under a directory as Pair RDDs with key being a file name and values being the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/applenews_sm.txt', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/README.md', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/filtered_registered_business_sf.csv', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/applenews.txt', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/supervisor_sf.csv', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/USF_Mission.txt', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/ignatian_pedagogy', u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/sm.txt']\n",
      "(u'file:/Users/tlee010/Desktop/github_repos/learning-deep/msan694_disco/examples/Data/applenews_sm.txt', u'Jony Ive, technically Apple\\u2019s design chief since 2015, is once again assuming management control of the iPhone maker\\u2019s design team after two years in a largely hands-off role, according to a report from Bloomberg. Ive, responsible for the look and feel of Apple hardware throughout a majority of former CEO Steve Jobs\\u2019 revolutionary second run at the helm of the company in the late \\u201890s and 2000s, was freed from much of his day-to-day management responsibilities in 2015, when he took on the chief design officer title. He still oversaw design, but other executives and employees on the team no longer reported to him.\\n\\nAt the time, the move was viewed as Ive, who is 50 years old, laying the groundwork to retire from his intensive position at Apple. However, it now appears that Ive is retaking control. Apple\\u2019s leadership webpage no longer lists Alan Dye, the vice president of user interface design, or Richard Howarth, vice president of industrial design, according to 9to5Mac. Both Dye and Howarth took on Ive\\u2019s management responsibilities when he stepped back two years ago.')\n"
     ]
    }
   ],
   "source": [
    "files = sc.wholeTextFiles(\"./examples/Data\")\n",
    "print files.keys().collect()\n",
    "for file in files.take(1):\n",
    "    print file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: From \"supervisor_sf.csv”, filter data including “94103” and save under ”supervisor_94103”. Change the number of partitions, and see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"./examples/Data/supervisor_sf.csv\",6) #Try to change the number of partitions.\n",
    "filtered_lines = lines.filter(lambda x: \"94103,\" in x) #.repartition(1) generates one file.\n",
    "# filtered_lines.saveAsTextFile(\"supervisor_94103\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 : \n",
    "- Load ”example.json”.\n",
    "  - Filter item that has 3 in “array”.\n",
    "  - Convert the filtered output in JSON format and save in “json_data_with_3” folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'{\"ID\":\"id_1\",\"array\":[1,2,3],\"dict\": {\"key\": \"value1\"}}', u'{\"ID\":\"id_2\",\"array\":[2,4,6],\"dict\": {\"key\": \"value2\"}}', u'{\"ID\":\"id_3\",\"array\":[3,6,9],\"dict\": {\"key\": \"value3\", \"extra_key\": \"extra_value3\"}}']\n",
      "----------------\n",
      "[{u'array': [1, 2, 3], u'dict': {u'key': u'value1'}, u'ID': u'id_1'}, {u'array': [2, 4, 6], u'dict': {u'key': u'value2'}, u'ID': u'id_2'}, {u'array': [3, 6, 9], u'dict': {u'key': u'value3', u'extra_key': u'extra_value3'}, u'ID': u'id_3'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_input = sc.textFile(\"./examples/Data/example.json\")\n",
    "json_data = json_input.map(lambda x:json.loads(x))\n",
    "print json_input.collect() #text file\n",
    "print '----------------'\n",
    "print json_data.collect() #json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data_with_3 = json_data.filter(lambda x: 3 in x['array'] )\n",
    "#json_data_with_3.map(lambda x : json.dumps(x)).saveAsTextFile('json_data_with_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4:\n",
    "Read data from supervisor_sf.csv as a dictionary structure of (Zip, Supervisor). Choose Zip starting with “94”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
