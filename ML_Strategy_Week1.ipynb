{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why ML Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect more data\n",
    "Collect more diverse training data\n",
    "\n",
    "# There's so much to try\n",
    "\n",
    "### What to tune, to get what effect\n",
    "\n",
    "## Orthogonalization\n",
    "\n",
    "Example: old TV set had different knobs to adjust different parts of the picture. If you had a knob that changed different parts of each item, it would be impossible to tune the TV.\n",
    "\n",
    "Car\n",
    "\n",
    "Steering wheel - left and right\n",
    "Gas + break - speed\n",
    "\n",
    "Imagine if you had a control that did 0.3 speed + 0.4 left. Much harder to control the car then isolated dimension driving. \n",
    "\n",
    "This is orthogonal controls (independent controls) aligned with aspect you want to control. \n",
    "\n",
    "#### Assumptions\n",
    "\n",
    "1. Fit Training set well on cost function (close to human level performance)\n",
    "\n",
    "2. Fit dev set well on cost function\n",
    "\n",
    "3. Fit test set well on cost function\n",
    "\n",
    "4. Performs well in the real world\n",
    "\n",
    "#### Knobs\n",
    "\n",
    "1. Fit Training set well on cost function (close to human level performance)\n",
    "    - **bigger network**\n",
    "    - **adam**\n",
    "    - Some people use early stopping, but it really affects two things\n",
    "\n",
    "2. Fit dev set well on cost function\n",
    "    - **Regularization**\n",
    "    - **bigging training set**\n",
    "\n",
    "3. Fit test set well on cost function\n",
    "    - **Bigger dev set**\n",
    "\n",
    "4. Performs well in the real world\n",
    "    - **change dev set**\n",
    "    - **change the cost function**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Number Evaluation Metric\n",
    "\n",
    "#### How to measure how well your model is doing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say you decide to use precision as your main metric for measuring models. \n",
    "\n",
    "**Example 1** The simplest example is that we are making a model and decide to track both the precision and the recall for the model. Which is the more important metric?\n",
    "\n",
    "\n",
    "**Example 2** You have different models that work with differing performance depending on the market. How would you decide on the tradeoffs between the different markets for the \"better\" model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisfying and Optimizing Metric\n",
    "\n",
    "**Example 1:** you are training a model that you are tracking the accuracy and running time. \n",
    "\n",
    "The cost function for this would be \n",
    "\n",
    "accuracy - 0.5 running Time\n",
    "\n",
    "You may want to maximize the accuracy and satisficing the running time with a threshold < 100 ms. \n",
    "\n",
    "Maximize (accuracy | < 100 ms )\n",
    "\n",
    "** Example 2: ** Say you are detecting wake words. Either \"alexa\" or hey \"siri\". You might care about accuracy. You might also care about number of false positives. \n",
    "\n",
    "Maximize ( accuracy | 1 false positive every 24 hours)\n",
    "\n",
    "How to setup training dev and test sets for these unique metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Dev / test distributions for new Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev is also called the holdout set. Use it to develop, then finally score on the test set.\n",
    "\n",
    "Lets say your dataset has multiple regions:\n",
    "- US\n",
    "- UK\n",
    "- Other Europe\n",
    "- South America\n",
    "- India\n",
    "- China\n",
    "- Other Asia\n",
    "- Austrailia\n",
    "\n",
    "What if your dev was [ US, UK, Other Europa, South America]? \n",
    "\n",
    "**BAD** - they come from different distributions. \n",
    "\n",
    "Shuffle the test and dev steps to mix regions\n",
    "\n",
    "** Example: Optimizing dev on loan approvals for medium income zip codes**\n",
    "\n",
    "The team tested it on low income zip codes, and the classifier didn't do so well. They spent 3 months aiming at one target and then tested on a completely different test set\n",
    "\n",
    "\n",
    "#### Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the dev and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The guidelines are changing. \n",
    "\n",
    "**Previously :** \n",
    "- 70 / 30 ratio was used for training and test set. \n",
    "- Or 60 / 30 / 10 for train / dev / test\n",
    "\n",
    "** Now: ** \n",
    "- if you have a millions data points. \n",
    "- You may want 98%, 1% , 1% for train , dev, test. Since the datasets are so large, its fine using a much smaller % for the test and dev sets. \n",
    "\n",
    "#### Set your test set to be big enough to give high confidence in the overall performance of your system\n",
    "\n",
    "No test set may be ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to change dev / test sets and metrics\n",
    "\n",
    "**Example :** Cat dataset\n",
    "\n",
    "- Algo A: 3% error - but has NSFW images\n",
    "- Algo B: 5% error\n",
    "\n",
    "In this case algo B is better because of the NSFW image score. \n",
    "\n",
    "Error : \n",
    "\n",
    "$$ \\frac{1}{m_{dev}} \\sum_{i=1}^{m_{dev}}w^{(i)}L(y_{pred}^{(i)} - y^{(i)})$$\n",
    "\n",
    "Where $w^{(i)}$ will be defined on the examples that you want to penalize\n",
    "\n",
    "1. So far we've only discussed how to define a metric to evaluate classifiers. ** place the target to aim at ** \n",
    "\n",
    "2. Worry separately about how to do well on this metric. **Aim / shoot at the target **\n",
    "\n",
    "\n",
    "**Example 2:** Cat dataset\n",
    "\n",
    "- Algo A: 3% error \n",
    "- Algo B: 5% error - seems to be doing better\n",
    "\n",
    "This might be because we trained on hi-def images, but the user submission images are blurry and poor.\n",
    "\n",
    "#### if doing well on your metric + dev/test set does not correspond to doing well on your application, change yoru metric and/ or dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to human-level performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some poiint after reaching human level performance, the performance tapers out, and improvement eventually assymptotes and flatlines. \n",
    "\n",
    "- Get labeled data from humans\n",
    "- gain insight from manual error analysis WHy did a person get this right?\n",
    "- Better analysis of bias / variance\n",
    "\n",
    "But once hte model hits human level performance, its hard to use these methods to improve the model anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoidable Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "- Human Error 1%\n",
    "- Training Error: 8%\n",
    "- Dev Error 10%\n",
    "\n",
    "#### Focus on bias, reduce the training error.\n",
    "\n",
    "But what if human error is quite bad (pictures are blurry)\n",
    "\n",
    "- Human Error 7.5%\n",
    "- Training Error: 8%\n",
    "- Dev Error 10%\n",
    "\n",
    "#### Focus on variance to match the training vs. dev error, since there isn't much error to improve on for the training error.\n",
    "\n",
    "#### use human level error as a proxy for bayes error.\n",
    "\n",
    "### Don't try ( can't ) do better than Bayes error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Human level performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medical image classification example\n",
    "\n",
    "Suppose:\n",
    "    \n",
    "- Typical human 3% error\n",
    "- Typical Doctor 1% error\n",
    "- Experienced Docto 0.7% error\n",
    "- Team of experienced doctors 0.5% error\n",
    "\n",
    "Whats the bayes error? These are all humans? ** the team of doctors **\n",
    "\n",
    "- Huamn ~1, 0.7, 0.5%\n",
    "- Training Error 5%\n",
    "- Dev Error 6% \n",
    "\n",
    "The gap between Bayes error + training error is the avoidable bias. In this case teh avoidable bias is 4%. The variance is only 1% between training and dev sets.\n",
    "\n",
    "- Huamn ~1, 0.7, 0.5%\n",
    "- Training Error 1%\n",
    "- Dev Error 5% \n",
    "\n",
    "The \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
