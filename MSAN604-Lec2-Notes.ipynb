{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSAN 604 Sec2Lec2 Notes: RDDs, Transformations, Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to run the code, please note where your dataset is and also that you have started the notebook at the command line using:\n",
    "\n",
    "```bash\n",
    "$pyspark\n",
    "```\n",
    "\n",
    "which should open jupyter notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.1.45.27:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a RDD?\n",
    "\n",
    "\n",
    "![alt text](http://backtobazics.com/wp-content/themes/twentyfourteen/images/spark/spark-rdd.png)\n",
    "\n",
    "RDD is a distributed file set split over partitions in a data cluster. This is represented in spark as a single dataset called RD.\n",
    "\n",
    "**Partition**: a \"subset\". In computer terms, you may have 1TB, but you can put some walls up to subdivide the drive into 2 drives of 500 GB, or 3 drives of 250, 250, 500 GB.\n",
    "\n",
    "** By default, max number of partitions is number of threads that you computer has **\n",
    "** Example: if your computer has a quad core intel, each has 2 threads so 4 x2 = 8 available cores, 8 partitions**\n",
    "\n",
    "Some features:\n",
    "\n",
    "1. Distributed -> over different partitions\n",
    "2. Immutable -> read only\n",
    "3. Resilient -> if one node dies, cluster will be rebuilt. (Not replication). The data will rebuilt by the instructions supplied by the master note\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulations - Transformations + Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/3QiV8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD - Transformations: change RDD's and return RDDs\n",
    "\n",
    "### RDD - Actions: take RDD's and return values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://trongkhoanguyen.com/assets/post-images/2014/rdd-operations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/README.md'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from readme markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/README.md MapPartitionsRDD[8] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(filepath)\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[9] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.parallelize([\"spark\",\"spark is fun!\"])\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Shows all the partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note - **`collect`** is a mapping function that is forcing a evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], ['spark'], [], [], [], ['spark is fun!']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Shows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'spark is fun!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add more data\n",
    "\n",
    "- add an option for how many partitions it needs to be divided by\n",
    "- sc.parallelize( data, no_of_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spark', 'spark is fun!'], ['1', '2'], ['3', '4'], ['5', '6', '7', '8']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.parallelize([\"spark\",\"spark is fun!\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"],4)\n",
    "lines.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda functions\n",
    "\n",
    "These are one-time functions are executed at run-time. These are also considered anonymus functions. A lot of times you don't have to name the functions.\n",
    "\n",
    "Example of a regular function\n",
    "```python\n",
    "def f(x):\n",
    "    return x+2\n",
    "```\n",
    "\n",
    "Inline equivalent\n",
    "```python\n",
    "lambda x : x+2\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Operations\n",
    "\n",
    "1. Transformations\n",
    "\n",
    "**RDDs when changed:** Make a new RDD when manipulating an old RDD (this is because all RDDs are immutable). So any changes must mean a new data set has to be stored to a new dataset.\n",
    "    \n",
    "    \n",
    "    ```python\n",
    "    # only want lines that have the word 'spark\" in it\n",
    "    lines_with_spark = lines.filter(lambda lines : 'spark' in lines)\n",
    "    ```\n",
    "    \n",
    "**Lazy evaluation**: the above filtering function has been setup BUT HAS NOT BEEN EXECUTED. This will only be executed when the `lines_with_spark` is called in another function\n",
    "\n",
    "**Sample Transformation functions:** \n",
    "\n",
    "- map\n",
    "- filter\n",
    "- flatMAP\n",
    "- mapPartitions\n",
    "\n",
    "** Example: Map (on Elements)**\n",
    "\n",
    "\n",
    "Typical methods that take a function and apply element wise\n",
    "- map(func)\n",
    "\n",
    "- flatmap(func)\n",
    "\n",
    "- filter(func)\n",
    "\n",
    "\n",
    "Element wise transformation methods, even across partitions. \n",
    "\n",
    "**Example**, lets say you have a dataset [1,2,3,4] split over 2 partitions:\n",
    "\n",
    "    Partition 1 \n",
    "    1, 2\n",
    "\n",
    "    Partition 2\n",
    "    3, 4\n",
    "\n",
    "`map(f(x))` will do the following:\n",
    "\n",
    "    Partition 1 \n",
    "    f(1), f(2)\n",
    "\n",
    "    Partition 2\n",
    "    f(3), f(4)\n",
    "    \n",
    "**Example** let's say you have a dataset:\n",
    "```python\n",
    "'I love tacos'\n",
    "'I love coffee'\n",
    "```\n",
    "**map function under** `.map(lambda x : x.split())`\n",
    "\n",
    "```python\n",
    "[['I','love','taco']\n",
    "  ['I','love','coffee']]\n",
    "```\n",
    "\n",
    "Note the nested list structure\n",
    "\n",
    "**flat map** under `.flatmap(lambda x : x.split())`\n",
    "\n",
    "\n",
    "```python\n",
    "['I','love','taco','I','love','coffee']\n",
    "```\n",
    "\n",
    "Note the flat list structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclass Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'= Ignatian Values =',\n",
       " u'The University of San Francisco enjoys a distinguished heritage and Jesuit tradition.  At the core of this tradition are transcendent values, including the integration of learning, faith and service; care for the whole person; character and conviction; religious truth and interfaith understanding; and a commitment to building a more just world.  The key values of this Jesuit tradition are as follows:',\n",
       " u'***********************************************************************************',\n",
       " u\"1. Contemplative in Action - St. Ignatius Loyola believed that prayer and reflectivity should so guide our choices and actions that our activity itself becomes a way of entering into union with and praising God.  Being a contemplative in action also means seeing beyond the superficial in life to appreciate the mystery, beauty, and sacredness of all life.  It is a means of seeing God in all things and in everyone.  Contemplation is a critical dimension of the spiritual life and it is reflected in USF's commitment to prayer and spiritual growth.  Analogously, in the academic life, a spirit of reflectivity is a critical aspect of intellectual inquiry.\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads in a CSV flat text file\n",
    "lines = sc.textFile(filepath)\n",
    "\n",
    "# collects all the different terms\n",
    "lines.collect()[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the words using the map function (should have nested lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'=', u'Ignatian', u'Values', u'='],\n",
       " [u'The',\n",
       "  u'University',\n",
       "  u'of',\n",
       "  u'San',\n",
       "  u'Francisco',\n",
       "  u'enjoys',\n",
       "  u'a',\n",
       "  u'distinguished',\n",
       "  u'heritage',\n",
       "  u'and',\n",
       "  u'Jesuit',\n",
       "  u'tradition.',\n",
       "  u'At',\n",
       "  u'the',\n",
       "  u'core',\n",
       "  u'of',\n",
       "  u'this',\n",
       "  u'tradition',\n",
       "  u'are',\n",
       "  u'transcendent',\n",
       "  u'values,',\n",
       "  u'including',\n",
       "  u'the',\n",
       "  u'integration',\n",
       "  u'of',\n",
       "  u'learning,',\n",
       "  u'faith',\n",
       "  u'and',\n",
       "  u'service;',\n",
       "  u'care',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'whole',\n",
       "  u'person;',\n",
       "  u'character',\n",
       "  u'and',\n",
       "  u'conviction;',\n",
       "  u'religious',\n",
       "  u'truth',\n",
       "  u'and',\n",
       "  u'interfaith',\n",
       "  u'understanding;',\n",
       "  u'and',\n",
       "  u'a',\n",
       "  u'commitment',\n",
       "  u'to',\n",
       "  u'building',\n",
       "  u'a',\n",
       "  u'more',\n",
       "  u'just',\n",
       "  u'world.',\n",
       "  u'The',\n",
       "  u'key',\n",
       "  u'values',\n",
       "  u'of',\n",
       "  u'this',\n",
       "  u'Jesuit',\n",
       "  u'tradition',\n",
       "  u'are',\n",
       "  u'as',\n",
       "  u'follows:'],\n",
       " [u'***********************************************************************************']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.map(lambda line: line.split())\n",
    "\n",
    "# each of the lines is essentially a paragraph\n",
    "words.collect()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclass Problem - do the same above exercise, but do it using a flatMap command`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'=',\n",
       " u'Ignatian',\n",
       " u'Values',\n",
       " u'=',\n",
       " u'The',\n",
       " u'University',\n",
       " u'of',\n",
       " u'San',\n",
       " u'Francisco',\n",
       " u'enjoys']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line: line.split())\n",
    "words.collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2 : filter by 'USF'\n",
    "\n",
    "#### using a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"USF's\", u'USF', u\"USF's\", u\"USF's\", u'USF', u'USF', u'USF', u'USF']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line: [x for x in line.split() if 'USF' in x])\n",
    "words.collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"USF's\", u'USF', u\"USF's\", u\"USF's\", u'USF', u'USF', u'USF', u'USF']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line: [x for x in line.split() if 'USF' in x])\n",
    "filtered_words = words.filter(lambda x: 'USF' in x )\n",
    "filtered_words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Based Operations\n",
    "\n",
    "\n",
    "**Remember the Example**, lets say you have a dataset [1,2,3,4] split over 2 partitions:\n",
    "\n",
    "    Partition 1 \n",
    "    1, 2\n",
    "\n",
    "    Partition 2\n",
    "    3, 4\n",
    "\n",
    "`map(f(x))` will do the following:\n",
    "\n",
    "    Partition 1 \n",
    "    f(1), f(2)\n",
    "\n",
    "    Partition 2\n",
    "    f(3), f(4)\n",
    "    \n",
    "Creates a connection & function per element, very computationally expensive. **What about doing it at a partition level ( level above)?**\n",
    "\n",
    "This is done by creating a **iterator**. A iterator is a data structure that works like a cursor. It starts at the beginning of a list and only feeds the next element when the process is ready. Simplest python example is as follows:\n",
    "\n",
    "`[0,1,2,3,4,5,6]` vs. `xrange(6)`\n",
    "\n",
    "\n",
    "### Inclass example: parallelize numbers between 1 and 16. Calculate the count and sum in each partition.\n",
    "\n",
    "In 4 partitions:\n",
    "\n",
    "```python\n",
    "\n",
    "[1,2] [3,4] [ 5,6], [7,8]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "(2,3) (2,7)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make a function for map partioins()\n",
    "\n",
    "lets make a sample numbers dataset for 16 numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(1,17))\n",
    "numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_sum(nums):\n",
    "    \n",
    "    # making our own list to hold two things\n",
    "    # first the count\n",
    "    # the sum\n",
    "    count_sum = [0,0]\n",
    "    \n",
    "    for num in nums:\n",
    "        # will count the quantity of floats\n",
    "        count_sum[0] += 1\n",
    "        # will sum the actual values of the floats\n",
    "        count_sum[1] += num\n",
    "        \n",
    "    # returning a nested list\n",
    "    return [count_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the answer is for each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [2, 7], [2, 11], [2, 15], [2, 19], [2, 23], [2, 27], [2, 31]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse = numbers.mapPartitions(count_sum)\n",
    "parse.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to get the total sum overall partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 136]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_sum = parse.reduce(lambda x,y: [x[0]+y[0],x[1]+y[1]])\n",
    "total_count_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Spark program in a Python script (instead of notebooks)\n",
    "\n",
    "Know this for the test. The submissions are going to be in .py\n",
    "\n",
    "## Within your python file\n",
    "\n",
    "#### import your libraries\n",
    "```python\n",
    "from pyspark import SparkConf, SparkContext\n",
    "```\n",
    "\n",
    "#### Set the configuration files. \n",
    "\n",
    "- **Appname** = the name program or 'job' when its sent to the cluster to be run.\n",
    "- **local[\\*]** = the cluster or program that you are connecting to. Would be a URL if connecting to a system\n",
    "\n",
    "```python\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"AppName\")\n",
    "```\n",
    "\n",
    "#### start your pyspark context (program envir)\n",
    "```python\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "# when done call\n",
    "sc.stop()\n",
    "```\n",
    "\n",
    "## At the command line\n",
    "\n",
    "#### Check current setup\n",
    "\n",
    "```bash\n",
    "$echo $PYSPARK_DRIVER_PYTHON\n",
    "jupyter\n",
    "\n",
    "$echo $PYSPARK_DRIVER_PYTHON_OPTS\n",
    "notebook\n",
    "\n",
    "```\n",
    "\n",
    "#### Unset your environment variables\n",
    "\n",
    "```bash\n",
    "$unset PYSPARK_DRIVER_PYTHON\n",
    "$echo PYSPARK_DRIER_PYTHON\n",
    "\n",
    "$unset PYSPARK_DRIVER_PYTHON_OPTS\n",
    "$echo PYSPARK_DRIVER_PYTHON_OPTS\n",
    "```\n",
    "\n",
    "#### Run your standalone program\n",
    "```bash\n",
    "# too much output! but will print to screen\n",
    "$spark-submit ex6.py\n",
    "\n",
    "# will still print to console, but the ouput only will write to a file\n",
    "$spark-submit ex6.py > output.txt\n",
    "```\n",
    "\n",
    "#### Reset the environment variables\n",
    "\n",
    "```bash\n",
    "$ nano ~/.bash_profile\n",
    "```\n",
    "\n",
    "#### Within your bash profile - reset the defaults back to jupyter notebook\n",
    "\n",
    "```bash\n",
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "export PYSPARK_DRIVER_PYTHON=\"notebook\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of HW1 assignment, and submission\n",
    "\n",
    "Split by word, but if number, add the values together. Going over the assignment PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Operation-Transformations\n",
    "\n",
    "- distinct()\n",
    "- union()\n",
    "- intersection()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Operation-Action\n",
    "\n",
    "Compute on RDD, but return non-RDD answers. \n",
    "\n",
    "- only those covered in class will be on quiz (see below)\n",
    "```python\n",
    "reduce()\n",
    "collect()\n",
    "count()\n",
    "```\n",
    "\n",
    "others\n",
    "```\n",
    "fold()\n",
    "aggregate()\n",
    "```\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    ">>> num = [1, 2] [3, 4] [5, 6] [7, 8]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> num.reduce(lambda x,y: x + y)\n",
    "```\n",
    "\n",
    "What happens under the hood\n",
    "\n",
    "`[1 + 2] [3 + 4] [5 + 6] [7 + 8]`\n",
    "\n",
    "`[x + y] [x + y] [x + y] [x + y]`\n",
    "\n",
    "Reduces x's and y's by partition\n",
    "\n",
    "`[3] [7] [11] [15]`\n",
    "\n",
    "`[3]+[7] <-[11]<- [15]`\n",
    "\n",
    "\n",
    "\n",
    "Then condenses (there's a lot of options here, so not guaranteed to be the exact process)\n",
    "\n",
    "    `[10]<-[11]`\n",
    "\n",
    "        `[21]<- [15]`\n",
    "\n",
    "            `[36]`\n",
    "\n",
    "** Fold example **\n",
    "\n",
    "```python\n",
    ">>> num.fold(0)(lambda x,y: x + y)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "What happens under the hood, note the empty partition on the right. The fold(0) will give a default value and prevent a computation error\n",
    "\n",
    "`[1 + 2] [3 + 4] [5 + 6] [7 + 8] []`\n",
    "\n",
    "`[0+ x + y] [0 + x + y] [0 + x + y] [0 + x + y] [0]`\n",
    "\n",
    "Reduces x's and y's by partition\n",
    "\n",
    "`[3] [7] [11] [15] [0]`\n",
    "\n",
    "`[3]+[7] <-[11]<- [15] <- [0]`\n",
    "\n",
    "\n",
    "\n",
    "Then condenses\n",
    "\n",
    "    `[10]<-[11]`\n",
    "\n",
    "        `[21]<- [15]`\n",
    "\n",
    "            `[36]`\n",
    "\n",
    "\n",
    "** In class Example 4-1 calculate sum of odd nubmers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(1,17))\n",
    "numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOdd(x):\n",
    "    if x % 2 == 1:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = numbers.map(lambda x: x if x %2==1 else 0) \n",
    "temp1 = numbers.filter(lambda x: x%2==1) \n",
    "temp2 = temp1.reduce(lambda x,y : x+y)\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda x,y : 0 if x&2 == 0 else 0 if y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD operation-actions (to be used with reduce)\n",
    "\n",
    "Numeric RDD action Types\n",
    "\n",
    "- count()\n",
    "- collect()\n",
    "- countByValue()\n",
    "- top(n)\n",
    "- take(n)\n",
    "- first()\n",
    "- takeSample()\n",
    "- foreach()\n",
    "- mean()\n",
    "- sum()\n",
    "- max()\n",
    "- min()\n",
    "- variance()\n",
    "- stdev()\n",
    "\n",
    "Sample for a RDD\n",
    "\n",
    "```python\n",
    "rdd_variable.sum()\n",
    "rdd_variable.top()\n",
    "rdd_variable.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclass exercise - the number of distinct values \n",
    "\n",
    "from a pedagogy file in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pedagog = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'all', 3),\n",
       " (u'enrollment.', 1),\n",
       " (u'themes', 1),\n",
       " (u'religious', 2),\n",
       " (u'Today', 1),\n",
       " (u'relationships', 1),\n",
       " (u'young', 1),\n",
       " (u'to', 17),\n",
       " (u'Reflecting', 1),\n",
       " (u'discovering', 1)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pedagog.flatMap(lambda x : x.split())\n",
    "summary = words.countByValue()\n",
    "summary.items()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Additional Exercises from the Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-1 Load Text file and split line by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'=', u'Ignatian', u'Values', u'='],\n",
       " [u'The', u'University', u'of', u'San'],\n",
       " [u'***********************************************************************************'],\n",
       " [u'1.', u'Contemplative', u'in', u'Action'],\n",
       " [],\n",
       " [u'2.', u'Academic', u'Excellence', u'-'],\n",
       " [],\n",
       " [u'3.', u'Educating', u'the', u'Whole'],\n",
       " [],\n",
       " [u'4.', u'\"Cura', u'Personalis\"', u'-']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.map(lambda line : line.split())\n",
    "\n",
    "# print sample results, will only print top 4 of every list \n",
    "results = words.glom().collect() # limited to 2 items for viewing ease\n",
    "map( lambda x: x[:4],results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-2 Generate a list of words within one level structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'=', u'Ignatian', u'Values', u'=', u'The']\n",
      "[u'5.', u'Women', u'and', u'Men', u'for']\n",
      "\n",
      "[u'=', u'Ignatian', u'Values', u'=', u'The', u'University', u'of', u'San', u'Francisco', u'enjoys']\n"
     ]
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "\n",
    "# print sample results, will only print top 5 of every list \n",
    "results = words.glom().collect()\n",
    "for x in map( lambda x: x[:5],results):\n",
    "    print x\n",
    "\n",
    "# or make flat with collect()\n",
    "results = words.collect()\n",
    "print '\\n', results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-3 Find words USF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### note that if we use `map` when breaking lines, it will filter which LIST has USF in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- original split into words\n",
      "[u'=', u'Ignatian', u'Values', u'=']\n",
      "[u'The', u'University', u'of', u'San']\n",
      "[u'***********************************************************************************']\n",
      "[u'1.', u'Contemplative', u'in', u'Action']\n",
      "[]\n",
      "[u'2.', u'Academic', u'Excellence', u'-']\n",
      "[]\n",
      "[u'3.', u'Educating', u'the', u'Whole']\n",
      "[]\n",
      "[u'4.', u'\"Cura', u'Personalis\"', u'-']\n",
      "----------------- only collections with USF\n",
      "[u'2.', u'Academic', u'Excellence', u'-']\n"
     ]
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.map(lambda line : line.split())\n",
    "usf_words = words.filter(lambda w: 'USF' in w)\n",
    "\n",
    "# print sample results, will only print top 5 of every list \n",
    "results = words.glom().collect() # limited to 2 items for viewing ease\n",
    "print '----------------- original split into words'\n",
    "for x in map( lambda x: x[:4],results[0]):\n",
    "    print x\n",
    "\n",
    "# print sample results, will only print top 4 of every list \n",
    "results = usf_words.glom().collect() # limited to 2 items for viewing ease\n",
    "print '----------------- only collections with USF'\n",
    "for x in map( lambda x: x[:4],results[0]):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### note that if we use `mapFlat` when breaking lines, it will filter WORDS in the LIST that have USF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u\"USF's\", u'USF', u\"USF's\"], [u\"USF's\", u'USF', u'USF', u'USF', u'USF']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.flatMap(lambda line : line.split())\n",
    "usf_words = words.filter(lambda w: 'USF' in w)\n",
    "\n",
    "usf_words.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Parallelize numbers between 1 and 16\n",
    "\n",
    "Calculate the count and sum in each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(1,17),4)\n",
    "numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instead, if we return a 1 value list, we can get sums by partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 26, 42, 58]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = numbers.mapPartitions(lambda x: [sum(x)])\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3-1 \n",
    "Find distinct words in ignatian pedagogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'when',\n",
       " u'R,',\n",
       " u'including',\n",
       " u'computation',\n",
       " u'using:',\n",
       " u'guidance',\n",
       " u'Scala,',\n",
       " u'environment',\n",
       " u'only',\n",
       " u'rich',\n",
       " u'Apache',\n",
       " u'sc.parallelize(range(1000)).count()',\n",
       " u'Building',\n",
       " u'And',\n",
       " u'guide,',\n",
       " u'return',\n",
       " u'Please',\n",
       " u'[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       " u'Try',\n",
       " u'not']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/ignatian_pedagogy'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.flatMap(lambda x: x.split())\n",
    "distinct31 = words.distinct()\n",
    "distinct.collect()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3-2\n",
    "Create a flatmap of distinct words from “README.md”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'when',\n",
       " u'R,',\n",
       " u'including',\n",
       " u'computation',\n",
       " u'using:',\n",
       " u'guidance',\n",
       " u'Scala,',\n",
       " u'environment',\n",
       " u'only',\n",
       " u'rich',\n",
       " u'Apache',\n",
       " u'sc.parallelize(range(1000)).count()',\n",
       " u'Building',\n",
       " u'And',\n",
       " u'guide,',\n",
       " u'return',\n",
       " u'Please',\n",
       " u'[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       " u'Try',\n",
       " u'not']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/tlee010/Desktop/github_repos/2017-msan694-example/Data/README.md'\n",
    "lines = sc.textFile(filepath)\n",
    "words = lines.flatMap(lambda x: x.split())\n",
    "distinct32 = words.distinct()\n",
    "distinct.collect()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3-3\n",
    "What is union, intersection, subtract and cartesian product of the sets from Example 3-1 and Example 3-2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### union: joining 2 sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'when',\n",
       " u'R,',\n",
       " u'including',\n",
       " u'computation',\n",
       " u'using:',\n",
       " u'guidance',\n",
       " u'Scala,',\n",
       " u'environment',\n",
       " u'only',\n",
       " u'rich']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct32.union(distinct31).collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### intesection: only the common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'through',\n",
       " u'including',\n",
       " u'This',\n",
       " u'and',\n",
       " u'from',\n",
       " u'building',\n",
       " u'with',\n",
       " u'this',\n",
       " u'a',\n",
       " u'to']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct32.intersection(distinct31).collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subtract: differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'when',\n",
       " u'environment',\n",
       " u'Apache',\n",
       " u'Building',\n",
       " u'IDE,',\n",
       " u'return',\n",
       " u'Please',\n",
       " u'[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       " u'\"yarn\"',\n",
       " u'\"local\"']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct32.subtract(distinct31).collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cartesian multiply words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'when', u'1981,'),\n",
       " (u'when', u'all'),\n",
       " (u'when', u'just'),\n",
       " (u'when', u'Father'),\n",
       " (u'when', u'actions'),\n",
       " (u'when', u'discovered'),\n",
       " (u'when', u'schools'),\n",
       " (u'when', u'including'),\n",
       " (u'when', u'ecumenical'),\n",
       " (u'when', u'human')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct32.cartesian(distinct31).collect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4-1\n",
    "For the numbers between 1 and 9, calculate sum of the odd numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize(range(1,10))\n",
    "oddnum = numbers.filter(lambda x : x%2==1)\n",
    "print oddnum.collect()\n",
    "oddnum.reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4-2\n",
    "For the numbers between 1 and 9, calculate sum of the odd numbers using fold()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddnum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddnum.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddnum.fold(1,lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4-3\n",
    "\n",
    "Using aggregate(), return (sum, # of elements) of odd numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddnum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 25)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oddnum.aggregate((0,0),(lambda x,y: (x[0]+1,x[1]+y)),(lambda x,y : (x[0]+y[0],x[1]+y[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5-1\n",
    "Try collect(), count(), countByValue(), top(n), take(n), first(), takeSample() operations on z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [3], [], [4], [], [1], [], [2], [], [2], [], [3], [], [4], [], [5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 4, 1, 2, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([3,4,1,2])\n",
    "y = sc.parallelize(range(2,6))\n",
    "z = x.union(y)\n",
    "print z.glom().collect()\n",
    "z.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 2, 4: 2, 5: 1})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 4, 3]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.top(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 1, 2, 2]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2, 4, 5, 2]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.takeSample(False,6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
